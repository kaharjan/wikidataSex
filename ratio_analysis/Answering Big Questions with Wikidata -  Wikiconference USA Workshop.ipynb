{
 "metadata": {
  "name": "",
  "signature": "sha256:b1a0d2f3ab20f320930e58aa61d28c6dc6c5501ff2224d5d9f79cc07d45fb976"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Answering Big Questions with Wikidata\n",
      "##Wikiconference USA Workshop\n",
      "## Friday 30 May 2014\n",
      "###By Max Klein\n",
      "#### [@notconfusing](http://twitter.com/notconfusing)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Overview\n",
      "\n",
      "1. Motivate\n",
      "2. Previous Examples\n",
      "3. The shape of Wikidata data.\n",
      "3. Extended walkthrough.\n",
      "    2. Dependencies - Technological and Otherwise.\n",
      "    3. Wikidata Toolkit\n",
      "    4. Export and a Python munging pipeline.\n",
      "    5. Future Directions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Audience Gauge\n",
      "\n",
      "Who's comfortable with Wikidata as a concept?\n",
      "\n",
      "Who's comfortable with Wikidata's underlying structure?\n",
      "\n",
      "Who's comfortable looking at code examples?\n",
      "\n",
      "Who's ready to start hacking in this session?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Motivations and Past Examples\n",
      "\n",
      "**Answer *BIG* questions\u203d**\n",
      "\n",
      "+ Interwiki Comparison\n",
      "    + Compare coverage between Wikis\n",
      "        + Which is the most \"unique\" Wikipedia?\n",
      "        + Which is the least sex-biased Wikipedia?\n",
      "+ Aggregate \"wikiverse\" modelling.\n",
      "    + The word _for_ every language _in_ every language?\n",
      "+ New types of Queries\n",
      "    + How rich is our data?\n",
      "    + What does a map of all the subways in the world look like?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Interwiki Comparison\n",
      "\n",
      "The most unique Wikipedia\n",
      "\n",
      "<img src=\"LangLinks_linear.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Interwiki Comparison\n",
      "\n",
      "The least sex-biased Wikipedia\n",
      "\n",
      "<img src=\"Sex-Ratios-Wikidata-May-2014.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Aggregate Wikiverse Modelling\n",
      "\n",
      "The word _for_ every language _in_ every language?\n",
      "\n",
      "<img src=\"LanguagesByLanguages.png\">\n",
      "\n",
      "Reminder. It's not just Wikipedias, but Commons, Wikisource, Wikivoyage (and more to come.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#New Types of Queries\n",
      "What does the world look like according to data?\n",
      "<img src=\"dennymap.png\">\n",
      "\n",
      "[Attribution Denny Vrande\u0107i\u010d](http://www.tools.wmflabs.org/wikidata-analysis/map/map.html)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata - The Data-en-ing\n",
      "<blockquote>\n",
      "\"Wikidata data is complex.\"\n",
      "\n",
      "~ Markus Kr\u00f6tzsch\n",
      "</blockquote>\n",
      "\n",
      "Each item includes:\n",
      "\n",
      "+ Labels\n",
      "+ Descriptions\n",
      "+ Aliases\n",
      "+ Sitelinks\n",
      "+ Properties"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata the Data-en-ing\n",
      "\n",
      "These are the less semantic properties.\n",
      "\n",
      "+ Labels\n",
      "    + What the thing is called (in every language)\n",
      "+ Descriptions\n",
      "    + What the thing is, to distinguish if multiple things have the same label. \n",
      "    + e.g. Chinatowns, but in different cities.\n",
      "    + (No more disambiguation (with parens (in titles))) (in every language).\n",
      "+ Aliases\n",
      "    + Other labels that might refer to this item. \n",
      "    + Charles Babbage / Lewis Carroll.\n",
      "+ Sitelinks\n",
      "    + The Wikipedia articles in different languages that are associated with this item.\n",
      "    + Now also connecting Wikivoygae, Commons, and Wikisource.\n",
      "    + And this also shows Featured article badges."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata the Data-en-ing\n",
      "\n",
      "Properties. Prepare for the semantics.\n",
      "\n",
      "So the triple reads: \n",
      "\n",
      "[This item / page] [property] [value]\n",
      "\n",
      "+ Properties\n",
      "    + They can be many.\n",
      "        + Not necessarily agreeing\n",
      "    + Each has a value\n",
      "        + Which have different datatypes\n",
      "        + Which have references\n",
      "            + Which are also triples\n",
      "                + Which are read, this predicate, [property] [value]\n",
      "                    + E.g. this predicate, stated in, a reputable journal.\n",
      "    + And can also be prefered or deprecated.\n",
      "        + Known as the \"snak\"\n",
      "    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata Toolkit - The Need\n",
      "\n",
      "+ We can use the Javascript API - in fact that's what the interfact uses.\n",
      "\n",
      "+ But what about if you want lots of data?\n",
      "    + Maybe all the data\u203d\n",
      "\n",
      "+ Then you just have undocumented XML dumps.\n",
      "    + Which is where __Wikidata Toolkit__ comes in."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata Toolkit\n",
      "+ its from an Individual Engagement Grant\n",
      "+ Principal investigator is Markus Kr\u00f6tzsch\n",
      "+ The point is WDTK gives you Wikidata as Java objects\n",
      "+ Why Java?\n",
      "    + Because its for researchers\n",
      "    + And not necessarily Wikimedia hackers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata Toolkit\n",
      "##Features\n",
      "+ Uses daily incremental dumps\n",
      "    + Fresh enough\n",
      "+ Local, in-memory processing\n",
      "    + Fast\n",
      "+ Offline mode\n",
      "    + As stale as you like"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata Toolkit\n",
      "##Progress\n",
      "+ Started February 2014\n",
      "    + I used to use this python script that was slow and polluted this time in 2013\n",
      "+ 2 programmers on the project\n",
      "+ Currently at 0.1.0\n",
      "    + Next version's focus is on serialization.\n",
      "+ Can already get RDF dumps at tools.wmflabs.org/wikidatardfdumps (check link)\n",
      "    + Considered \"derived dumps\"\n",
      "    + have simple-statements\n",
      "    + includes subclass-of and instance-of."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata Toolkit\n",
      "##\"Standard Queiries\"\n",
      "There are no real 'standard queries'.\n",
      "    \n",
      "So you could also imagine queries like, \"which sources do I have to believe in order to beleive this statement.\"\n",
      "\n",
      "Don't stifle creativity.\n",
      "\n",
      "So in order to support \"tree shaped regular conjunctive path queries\", and \"star-shaped\" queries you get the freedom of the programming language rather than SQL-like chains."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "How many people came here expecting to look at code today?\n",
      "\n",
      "# To follow along, start downloading these packages.\n",
      "+ Wikidata Toolkit\n",
      "    + [On mediawiki](https://www.mediawiki.org/wiki/Wikidata_Toolkit)\n",
      "+ Pywikibot (optional)\n",
      "    + [Pywikibot](https://www.mediawiki.org/wiki/Manual:Pywikibot)\n",
      "+ IPython Notebook\n",
      "    + [Instructions](http://ipython.org/notebook.html)\n",
      "+ Pandas\n",
      "    + Use pip\n",
      "    \n",
      "##Additional assumptions\n",
      "+ You know what Wikidata is, in general."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Wikidata Toolkit Example\n",
      "\n",
      "go over all pages. If it has this property, bin it in two dimensions. By the way, I failed java classes twice in University, each time ending my formal education in programming. \n",
      "\n",
      "I understand this is the worst way to do it.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Modify DumpProcessingExample\n",
      "Just need minimally to edit one class which is the ItemStatisticsProcessor in DumpProcessingExample\n",
      "\n",
      "\n",
      "```\n",
      "\tstatic class ItemStatisticsProcessor implements EntityDocumentProcessor {\n",
      "\n",
      "\t\tlong countItems = 0;\n",
      "\t\t\n",
      "\t\tHashMap<String,Integer> lang_sexes = new HashMap<String,Integer>(); \n",
      "\n",
      "\n",
      "\t\t@Override\n",
      "\t\tpublic void processItemDocument(ItemDocument itemDocument) {\n",
      "\t\t\tthis.countItems++;\n",
      "\t\t\tfor (StatementGroup sg : itemDocument.getStatementGroups()) {\n",
      "\t\t\t\tfor (Statement si: sg.getStatements()) {\n",
      "\t\t\t\t\tString PID = si.getClaim().getMainSnak().getPropertyId().getId().toString();\n",
      "\t\t\t\t\tif (PID.equals(\"P21\")) {\n",
      "\t\t\t\t\t\tfor (String lang_string : itemDocument.getSiteLinks().keySet()) { \n",
      "\t\t\t\t\t\t\t/* should do this a better way at some point*/\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\tString ms = si.getClaim().getMainSnak().toString();\n",
      "\t\t\t\t\t\t\tString[] parts = ms.split(\"http://www.wikidata.org/wiki/Wikidata:Main_Page/\");\n",
      "\t\t\t\t\t\t\tString VID = parts[2].substring(0, parts[2].length()-1);\n",
      "\t\t\t\t\t\t\tString lang_sex_key = lang_string + \"--\" + VID;\n",
      "\t\t\t\t\t\t\tif (this.lang_sexes.get(lang_sex_key) != null ) {\n",
      "\t\t\t\t\t\t\t\tthis.lang_sexes.put(lang_sex_key, this.lang_sexes.get(lang_sex_key) + 1 );\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t\telse{\n",
      "\t\t\t\t\t\t\t\tthis.lang_sexes.put(lang_sex_key, 1);\n",
      "\t\t\t\t\t\t\t}\n",
      "\t\t\t\t\t\t}\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Output to JSON\n",
      "There's actually some more you need to edit to get the json out, but I'll let you see my document at this [github link](https://github.com/notconfusing/wikidataSex/blob/master/ratio_analysis/sexRatioProcessingExample.java)\n",
      "\n",
      "Here's one I made earlier..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Ahh lovely json and python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "from collections import defaultdict\n",
      "import pandas as pd\n",
      "import pywikibot\n",
      "import decimal\n",
      "NOPLACES = decimal.Decimal(10) ** 0\n",
      "TWOPLACES = decimal.Decimal(10) ** -2\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jsonfile = open('lang_sex.json','r')\n",
      "bigdict = json.load(jsonfile)\n",
      "lang_sex = defaultdict(dict)\n",
      "for keystring, count in bigdict.iteritems():\n",
      "    lang, sex = keystring.split('--')\n",
      "    lang_sex[lang][sex] = count"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sex_df = pd.DataFrame.from_dict(lang_sex, orient='index')\n",
      "sex_df = sex_df.fillna(value=0.0)\n",
      "sex_df"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#norm_sex is joke on heteronormativity\n",
      "norm_sex = sex_df.apply(lambda row: row / row.sum(), axis=1)\n",
      "norm_sex"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Tranforming QIDs into English labels.\n",
      "enwp = pywikibot.Site('en','wikipedia')\n",
      "wikidata = enwp.data_repository()\n",
      "\n",
      "def english_label(qid):\n",
      "    page = pywikibot.ItemPage(wikidata, qid)\n",
      "    data = page.get()\n",
      "    return data['labels']['en']"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sex_qs = [str(q) for q in norm_sex.columns]\n",
      "sex_labels = [english_label(sex_q) for sex_q in sex_qs]\n",
      "\n",
      "norm_sex.columns = sex_labels\n",
      "norm_sex"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sex_df['total'] = sex_df.sum(axis=1)\n",
      "\n",
      "female_sorted_1000_items = norm_sex[sex_df['total']>10000].sort('female', ascending=True)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "female_sorted_1000_items.plot(kind='bar', stacked=True, legend=True, figsize=(13,8), ylim=(0,1),\n",
      "                         title= '''Comoposition of Wikidata Prorerty:P21 \"Sex or Gender\" by Language \n",
      "    (Languages with over 1,000 associated P21)''')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Go put that on your fridge!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Step 3 become embroiled in gender-politics debates\n",
      "\n",
      "or optionally come to the Sunday hackathon and we look at producing your idea, or help work on doing this same analysis but using a time component, probably by decade."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Answering Big Questions with Wikidata\n",
      "##Wikiconference USA Workshop\n",
      "## Friday 30 May 2014\n",
      "###By Max Klein\n",
      "#### [@notconfusing](http://twitter.com/notconfusing)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}